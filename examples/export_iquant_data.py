# coding: gbk
"""
ä» iQuant å¯¼å‡ºè‚¡ç¥¨å†å²æ•°æ®ç”¨äºå¯¹æ¯”éªŒè¯

åŠŸèƒ½ï¼š
1. è¯»å– stock_list.txt ä¸­çš„è‚¡ç¥¨åˆ—è¡¨å’Œæ—¥æœŸèŒƒå›´
2. è°ƒç”¨ iQuant API è·å–å†å²Kçº¿æ•°æ®
3. å¯¼å‡ºæ”¶ç›˜ä»·æ•°æ®åˆ° predictions/iquant_data.csv

ä½¿ç”¨æ–¹æ³•ï¼š
1. åœ¨ iQuant å®¢æˆ·ç«¯ä¸­åŠ è½½æ­¤è„šæœ¬
2. ç¡®ä¿ predictions/stock_list.txt å·²ç”± qlib è„šæœ¬ç”Ÿæˆ
3. è¿è¡Œåä¼šåœ¨å®æ—¶ bar æ—¶è‡ªåŠ¨å¯¼å‡ºæ•°æ®
"""

import os
import pandas as pd
from datetime import datetime

# ===== é…ç½® =====
STOCK_LIST_PATH = r"D:\code\qlib\qlib\predictions\stock_list.txt"
OUTPUT_CSV_PATH = r"D:\code\qlib\qlib\predictions\iquant_data.csv"
# ================


def _parse_stock_list():
    """è§£æè‚¡ç¥¨åˆ—è¡¨æ–‡ä»¶ï¼Œæå–è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸèŒƒå›´"""
    if not os.path.isfile(STOCK_LIST_PATH):
        print(f"[é”™è¯¯] è‚¡ç¥¨åˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {STOCK_LIST_PATH}")
        print(f"[æç¤º] è¯·å…ˆè¿è¡Œ qlib å¯¼å‡ºè„šæœ¬ç”Ÿæˆ stock_list.txt")
        return [], None, None

    stocks = []
    start_date = None
    end_date = None

    with open(STOCK_LIST_PATH, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()

            # è§£ææ—¥æœŸèŒƒå›´
            if "æ—¥æœŸèŒƒå›´:" in line:
                parts = line.split("æ—¥æœŸèŒƒå›´:")
                if len(parts) > 1:
                    date_range = parts[1].strip()
                    dates = date_range.split("è‡³")
                    if len(dates) == 2:
                        start_date = dates[0].strip()
                        end_date = dates[1].strip()

            # è·³è¿‡æ³¨é‡Šè¡Œ
            if line.startswith("#") or not line:
                continue

            # è¯»å–è‚¡ç¥¨ä»£ç 
            stocks.append(line)

    return stocks, start_date, end_date


def _get_bar_data(ContextInfo, stock_code, start_date, end_date):
    """
    è·å–å•åªè‚¡ç¥¨çš„å†å²Kçº¿æ•°æ®

    å‚æ•°:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œæ ¼å¼å¦‚ '600000.SH'
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'

    è¿”å›:
        DataFrame with columns: date, close
    """
    try:
        # å…ˆä¸‹è½½å†å²æ•°æ®åˆ°æœ¬åœ°
        print(f"  [è°ƒè¯•] å…ˆä¸‹è½½å†å²æ•°æ®: {stock_code}")
        try:
            ContextInfo.download_history_data(
                stock_code=[stock_code],
                period='1d',
                start_time=start_date,
                end_time=end_date
            )
            print(f"  [æˆåŠŸ] å†å²æ•°æ®ä¸‹è½½å®Œæˆ")
        except Exception as e_download:
            print(f"  [è­¦å‘Š] ä¸‹è½½å†å²æ•°æ®å¤±è´¥: {e_download}")
            # ç»§ç»­å°è¯•è·å–æ•°æ®

        # ä½¿ç”¨æ¨èçš„ get_market_data_ex API
        # å‚è€ƒ _PyContextInfo.py çš„æç¤º
        print(f"  [è°ƒè¯•] è°ƒç”¨ get_market_data_ex({stock_code}, {start_date}, {end_date})")

        # get_market_data_ex çš„æ­£ç¡®å‚æ•°
        # å‚è€ƒ _PyContextInfo.py line 132
        kline = ContextInfo.get_market_data_ex(
            fields=['close'],          # æ­£ç¡®çš„å‚æ•°åæ˜¯ fields
            stock_code=[stock_code],
            period='1d',
            start_time=start_date,
            end_time=end_date,
            count=-1,
            dividend_type='none',      # ä¸å¤æƒ
            fill_data=False,
            subscribe=False
        )

        print(f"  [è°ƒè¯•] è¿”å›å€¼ç±»å‹: {type(kline)}")

        if kline is None:
            print(f"  [è­¦å‘Š] {stock_code} è¿”å› None")
            return pd.DataFrame()

        # get_market_data_ex è¿”å›çš„æ˜¯å­—å…¸æ ¼å¼
        # {è‚¡ç¥¨ä»£ç : DataFrame}
        if isinstance(kline, dict):
            print(f"  [è°ƒè¯•] è¿”å›å­—å…¸ï¼Œé”®: {list(kline.keys())}")

            # è·å–è¯¥è‚¡ç¥¨çš„æ•°æ®
            stock_data = kline.get(stock_code)

            # æ‰“å°æ•°æ®ç±»å‹å’Œå†…å®¹
            print(f"  [è°ƒè¯•] stock_data ç±»å‹: {type(stock_data)}")
            print(f"  [è°ƒè¯•] stock_data å†…å®¹: {stock_data}")

            if stock_data is None:
                print(f"  [è­¦å‘Š] {stock_code} è¿”å› None")
                return pd.DataFrame()

            # æ£€æŸ¥æ˜¯å¦æ˜¯ DataFrame
            if isinstance(stock_data, pd.DataFrame):
                print(f"  [è°ƒè¯•] è¿™æ˜¯ä¸€ä¸ª DataFrameï¼Œshape: {stock_data.shape}")
                print(f"  [è°ƒè¯•] åˆ—å: {list(stock_data.columns)}")
                print(f"  [è°ƒè¯•] å‰å‡ è¡Œ:\n{stock_data.head()}")

                if len(stock_data) == 0:
                    print(f"  [è­¦å‘Š] DataFrame ä¸ºç©º")
                    return pd.DataFrame()
            elif hasattr(stock_data, '__len__'):
                print(f"  [è°ƒè¯•] æ•°æ®é•¿åº¦: {len(stock_data)}")
                if len(stock_data) == 0:
                    print(f"  [è­¦å‘Š] {stock_code} æ•°æ®é•¿åº¦ä¸º 0")
                    return pd.DataFrame()
            else:
                print(f"  [è­¦å‘Š] æœªçŸ¥æ•°æ®ç±»å‹")
                return pd.DataFrame()

            print(f"  [è°ƒè¯•] æ•°æ®é•¿åº¦: {len(stock_data)}")
            print(f"  [è°ƒè¯•] ç¬¬ä¸€æ¡æ•°æ®: {stock_data[0] if len(stock_data) > 0 else 'N/A'}")

            # è§£ææ•°æ®
            records = []
            for i, item in enumerate(stock_data):
                try:
                    # get_market_data_ex è¿”å›çš„æ•°ç»„: [time, close]
                    if isinstance(item, (list, tuple)) and len(item) >= 2:
                        time_str = str(item[0])[:10] if item[0] else ''
                        close_val = float(item[1]) if item[1] is not None else None

                        if time_str and close_val is not None:
                            records.append({
                                "date": time_str,
                                "stock_code": stock_code,
                                "close": close_val
                            })
                    else:
                        print(f"  [è­¦å‘Š] ç¬¬ {i} æ¡æ•°æ®æ ¼å¼å¼‚å¸¸: {item}")

                except Exception as e:
                    print(f"  [è­¦å‘Š] è§£æç¬¬ {i} æ¡æ•°æ®å¤±è´¥: {e}")
                    continue

            if records:
                print(f"  [æˆåŠŸ] è§£æ {len(records)} æ¡æ•°æ®")
                return pd.DataFrame(records)
            else:
                print(f"  [è­¦å‘Š] æœªèƒ½è§£æä»»ä½•æ•°æ®")
                return pd.DataFrame()
        else:
            print(f"  [è­¦å‘Š] è¿”å›ç±»å‹ä¸æ˜¯å­—å…¸: {type(kline)}")
            return pd.DataFrame()

    except Exception as e:
        print(f"  [é”™è¯¯] è·å– {stock_code} æ•°æ®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def _preload_history_data(ContextInfo, stocks, start_date, end_date):
    """æå‰æ‰¹é‡ä¸‹è½½å†å²æ•°æ®ï¼Œä¾› handlebar ç›´æ¥è¯»å–ã€‚"""
    download_func = getattr(ContextInfo, "download_history_data", None)
    if not callable(download_func):
        print("[WARN] ContextInfo.download_history_data ä¸å¯ç”¨ï¼Œè·³è¿‡é¢„ä¸‹è½½")
        return False

    if not stocks:
        return False

    if not start_date or not end_date:
        return False

    print("\n[æ­¥éª¤0] é¢„ä¸‹è½½å†å²æ•°æ®...")
    success = False
    for code in stocks:
        try:
            download_func(
                stock_code=[code],
                period='1d',
                start_time=start_date,
                end_time=end_date,
            )
            success = True
            print(f"  [OK] å·²è§¦å‘ {code} {start_date} è‡³ {end_date} çš„å†å²æ•°æ®ä¸‹è½½")
        except Exception as exc:
            print(f"  [è­¦å‘Š] ä¸‹è½½ {code} å†å²æ•°æ®å¤±è´¥: {exc}")
    if success:
        print("[OK] å†å²æ•°æ®é¢„ä¸‹è½½å®Œæˆ")
    else:
        print("[WARN] æœªèƒ½æˆåŠŸé¢„ä¸‹è½½å†å²æ•°æ®")
    return success


def _ensure_history_for_date(ContextInfo, stock_code, date_str):
    """æŒ‰æ—¥å…œåº•è§¦å‘å†å²æ•°æ®ä¸‹è½½ï¼Œé˜²æ­¢ get_market_data_ex è¿”å›ç©ºã€‚"""
    if getattr(ContextInfo, "_history_preloaded", False):
        return True

    download_func = getattr(ContextInfo, "download_history_data", None)
    if not callable(download_func):
        return False

    cache = getattr(ContextInfo, "_history_cache", None)
    if cache is None:
        cache = set()
        ContextInfo._history_cache = cache

    cache_key = f"{stock_code}|{date_str}"
    if cache_key in cache:
        return True

    try:
        download_func(
            stock_code=[stock_code],
            period='1d',
            start_time=date_str,
            end_time=date_str,
        )
        cache.add(cache_key)
        print(f"  [INFO] å·²å…œåº•ä¸‹è½½ {stock_code} {date_str} çš„æ•°æ®")
        return True
    except Exception as exc:
        print(f"  [è­¦å‘Š] ä¸‹è½½ {stock_code} {date_str} æ•°æ®å¤±è´¥: {exc}")
        return False


def _extract_close_value(payload):
    """ä» ContextInfo æ¥å£è¿”å›çš„æ•°æ®é‡Œè§£æ close å€¼ã€‚"""
    if payload is None:
        return None, "payload ä¸º None"

    if isinstance(payload, pd.DataFrame):
        if "close" in payload.columns and not payload.empty:
            return float(payload["close"].iloc[-1]), f"DataFrame rows={len(payload)}"
        return None, f"DataFrame ç¼ºå°‘ close åˆ—æˆ–ä¸ºç©º columns={list(payload.columns)} size={payload.shape}"

    if isinstance(payload, dict):
        if "close" in payload:
            try:
                return float(payload["close"]), "dict['close']"
            except Exception as exc:
                return None, f"dict['close'] æ— æ³•è½¬æ¢: {exc}"

        # å¸¸è§å­—æ®µå°è¯•æ·±å…¥è§£æ
        for key in ("data", "values", "items", "records"):
            if key in payload:
                value = payload[key]
                result, reason = _extract_close_value(value)
                if result is not None:
                    return result, f"dict[{key}] -> {reason}"

        # å¦‚æœå­—å…¸åªæœ‰ä¸€ä¸ª valueï¼Œä¹Ÿå°è¯•æ·±å…¥
        if len(payload) == 1:
            value = next(iter(payload.values()))
            result, reason = _extract_close_value(value)
            if result is not None:
                return result, f"dict(single) -> {reason}"

        return None, f"dict keys={list(payload.keys())}"

    if isinstance(payload, (list, tuple)):
        if not payload:
            return None, "list/tuple ä¸ºç©º"

        for entry in payload:
            if isinstance(entry, dict):
                result, reason = _extract_close_value(entry)
                if result is not None:
                    return result, f"list(dict) -> {reason}"
            elif isinstance(entry, (list, tuple)) and len(entry) >= 2:
                close_candidate = entry[1]
                if close_candidate is not None:
                    try:
                        return float(close_candidate), f"list(tuple) sample={entry}"
                    except Exception as exc:
                        return None, f"list(tuple) close æ— æ³•è½¬æ¢: {exc}"
        return None, f"list å†…å®¹ç¤ºä¾‹: {payload[0]}"

    return None, f"æ— æ³•ä»ç±»å‹ {type(payload)} æå– close"


def _export_data(ContextInfo):
    """å¯¼å‡ºæ‰€æœ‰è‚¡ç¥¨çš„å†å²æ•°æ®"""
    print("\n" + "=" * 60)
    print("iQuant æ•°æ®å¯¼å‡ºå·¥å…·")
    print("=" * 60)

    # è¯»å–è‚¡ç¥¨åˆ—è¡¨
    print("\n[æ­¥éª¤1] è¯»å–è‚¡ç¥¨åˆ—è¡¨...")
    stocks, start_date, end_date = _parse_stock_list()

    if not stocks:
        print("  [é”™è¯¯] æœªæ‰¾åˆ°è‚¡ç¥¨åˆ—è¡¨")
        return

    print(f"  [OK] å·²è¯»å– {len(stocks)} åªè‚¡ç¥¨")
    print(f"  [OK] æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
    for stock in stocks:
        print(f"     - {stock}")

    # è·å–å†å²æ•°æ®
    print("\n[æ­¥éª¤2] è·å–å†å²Kçº¿æ•°æ®...")
    all_data = []

    for i, stock in enumerate(stocks, 1):
        print(f"  [{i}/{len(stocks)}] æ­£åœ¨è·å– {stock} ...")
        df = _get_bar_data(ContextInfo, stock, start_date, end_date)

        if not df.empty:
            all_data.append(df)
            print(f"      [OK] è·å– {len(df)} æ¡æ•°æ®")
        else:
            print(f"      [è­¦å‘Š] æ— æ•°æ®")

    if not all_data:
        print("\n[é”™è¯¯] æœªè·å–åˆ°ä»»ä½•æ•°æ®")
        return

    # åˆå¹¶æ•°æ®
    print("\n[æ­¥éª¤3] åˆå¹¶æ•°æ®...")
    final_df = pd.concat(all_data, ignore_index=True)
    print(f"  [OK] å…± {len(final_df)} æ¡æ•°æ®è®°å½•")
    print(f"  [ç»Ÿè®¡]")
    print(f"     - è‚¡ç¥¨æ•°é‡: {final_df['stock_code'].nunique()}")
    print(f"     - æ—¥æœŸæ•°é‡: {final_df['date'].nunique()}")
    print(f"     - å®é™…æ—¥æœŸèŒƒå›´: {final_df['date'].min()} è‡³ {final_df['date'].max()}")

    # ä¿å­˜åˆ° CSV
    print("\n[æ­¥éª¤4] ä¿å­˜æ•°æ®...")
    os.makedirs(os.path.dirname(OUTPUT_CSV_PATH), exist_ok=True)
    final_df.to_csv(OUTPUT_CSV_PATH, index=False, encoding="utf-8")
    print(f"  [OK] æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_CSV_PATH}")

    print("\n" + "=" * 60)
    print("[å®Œæˆ] æ•°æ®å¯¼å‡ºå®Œæˆï¼")
    print("=" * 60)


def init(ContextInfo):
    """åˆå§‹åŒ–å‡½æ•°"""
    print("\n" + "=" * 60)
    print("[iQuant] æ•°æ®å¯¼å‡ºè„šæœ¬å·²åŠ è½½")
    print("=" * 60)
    print(f"[iQuant] è‚¡ç¥¨åˆ—è¡¨è·¯å¾„: {STOCK_LIST_PATH}")
    print(f"[iQuant] è¾“å‡ºCSVè·¯å¾„: {OUTPUT_CSV_PATH}")

    # åˆå§‹åŒ–æ•°æ®æ”¶é›†åˆ—è¡¨
    ContextInfo._collected_data = []
    ContextInfo._bar_count = 0  # æ‰‹åŠ¨è®¡æ•° bar
    ContextInfo._history_cache = set()

    # ç«‹å³è¯»å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆä¸ç­‰åˆ° barpos=0ï¼‰
    print("\n[æ­¥éª¤1] è¯»å–è‚¡ç¥¨åˆ—è¡¨...")
    stocks, start_date, end_date = _parse_stock_list()

    if stocks:
        ContextInfo._stocks = stocks
        print(f"[INFO] âœ… æˆåŠŸè¯»å– {len(stocks)} åªè‚¡ç¥¨:")
        for stock in stocks:
            print(f"    - {stock}")
        print(f"[INFO] æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
    else:
        # ä½¿ç”¨ç¡¬ç¼–ç çš„ fallback åˆ—è¡¨
        print("[WARN] âš ï¸  æ— æ³•ä»æ–‡ä»¶è¯»å–è‚¡ç¥¨åˆ—è¡¨ï¼Œä½¿ç”¨ç¡¬ç¼–ç åˆ—è¡¨")
        ContextInfo._stocks = [
            "002594.SZ",
            "000002.SZ",
            "000001.SZ",
            "600519.SH",
            "600036.SH"
        ]
        print(f"[INFO] ä½¿ç”¨ {len(ContextInfo._stocks)} åªè‚¡ç¥¨")

    ContextInfo._start_date = start_date
    ContextInfo._end_date = end_date
    if start_date and end_date:
        ContextInfo._history_preloaded = _preload_history_data(ContextInfo, ContextInfo._stocks, start_date, end_date)
        if ContextInfo._history_preloaded:
            print(f"[INFO] âœ… å·²é¢„ä¸‹è½½ {start_date} è‡³ {end_date} çš„å†å²æ•°æ®")
        else:
            print("[WARN] æœªèƒ½é¢„ä¸‹è½½å†å²æ•°æ®ï¼Œå°†åœ¨ handlebar ä¸­é€æ—¥è§¦å‘ä¸‹è½½")
    else:
        ContextInfo._history_preloaded = False
        print("[WARN] stock_list.txt ç¼ºå°‘æ—¥æœŸèŒƒå›´ï¼Œhandlebar å°†æŒ‰æ—¥ä¸‹è½½å†å²æ•°æ®")

    print("=" * 60 + "\n")


def handlebar(ContextInfo):
    """
    handlebar åœ¨æ¯ä¸ª bar è§¦å‘
    åœ¨å›æµ‹ä¸­é€æ—¥æ”¶é›†æ•°æ®
    """
    # æ‰‹åŠ¨è®¡æ•° bar
    ContextInfo._bar_count = getattr(ContextInfo, '_bar_count', 0) + 1
    barpos = getattr(ContextInfo, 'barpos', -1)

    print(f"\n{'='*60}")
    print(f"[handlebar] Bar #{ContextInfo._bar_count} (barpos={barpos})")
    print('='*60)

    # æ£€æŸ¥è‚¡ç¥¨åˆ—è¡¨æ˜¯å¦å·²åŠ è½½
    if not hasattr(ContextInfo, '_stocks') or not ContextInfo._stocks:
        print("[ERROR] âŒ è‚¡ç¥¨åˆ—è¡¨æœªåˆå§‹åŒ–ï¼æ£€æŸ¥ init() å‡½æ•°")
        return

    # è·å–å½“å‰æ—¥æœŸ
    timetag = getattr(ContextInfo, 'get_bar_timetag', lambda x: None)(barpos)

    if not timetag:
        print(f"[WARN] âš ï¸  æ— æ³•è·å–æ—¶é—´æˆ³ (barpos={barpos})")
        return

    # è½¬æ¢æ—¶é—´æˆ³ä¸ºæ—¥æœŸå­—ç¬¦ä¸²
    date_str = datetime.fromtimestamp(timetag / 1000).strftime('%Y-%m-%d')
    print(f"[INFO] ğŸ“… å½“å‰æ—¥æœŸ: {date_str}")
    print(f"[INFO] ğŸ“Š å¼€å§‹æ”¶é›† {len(ContextInfo._stocks)} åªè‚¡ç¥¨çš„æ•°æ®...")

    # ä½¿ç”¨ get_history_data è·å–å½“å‰ bar çš„æ”¶ç›˜ä»·ï¼ˆæ­£ç¡®çš„æ–¹æ³•ï¼‰
    # åœ¨å›æµ‹æ¨¡å¼ä¸‹ï¼Œè¿™ä¸ªæ–¹æ³•ä¼šè¿”å›å½“å‰ bar å¯¹åº”æ—¥æœŸçš„å†å²æ•°æ®
    success_count = 0

    try:
        # å…ˆè®¾ç½®è‚¡ç¥¨æ± ï¼ˆget_history_data è¦æ±‚å…ˆè®¾ç½®ï¼‰
        ContextInfo.set_universe(ContextInfo._stocks)

        # è·å–å½“å‰ bar çš„æ”¶ç›˜ä»·æ•°æ®
        # len=1: è·å–1æ ¹Kçº¿ï¼ˆå½“å‰barï¼‰
        # period='1d': æ—¥çº¿
        # field='close': æ”¶ç›˜ä»·
        # dividend_type=0: ä¸å¤æƒ
        hisdict = ContextInfo.get_history_data(1, '1d', 'close', 0)

        print(f"[INFO] get_history_data è¿”å›ç±»å‹: {type(hisdict)}")

        # hisdict æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œkey æ˜¯è‚¡ç¥¨ä»£ç ï¼Œvalue æ˜¯æ”¶ç›˜ä»·æ•°ç»„
        if isinstance(hisdict, dict):
            print(f"[INFO] è¿”å› {len(hisdict)} åªè‚¡ç¥¨æ•°æ®")

            for i, stock in enumerate(ContextInfo._stocks, 1):
                if stock in hisdict:
                    close_data = hisdict[stock]

                    # æ‰“å°ç¬¬ä¸€åªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
                    if i == 1:
                        print(f"[è°ƒè¯•] {stock} æ•°æ®ç±»å‹: {type(close_data)}, å†…å®¹: {close_data}")

                    # close_data å¯èƒ½æ˜¯æ•°ç»„æˆ–å•ä¸ªå€¼
                    if isinstance(close_data, (list, tuple)) and len(close_data) > 0:
                        close_price = float(close_data[-1])  # å–æœ€åä¸€ä¸ª
                    elif isinstance(close_data, (int, float)):
                        close_price = float(close_data)
                    else:
                        print(f"  [{i}/{len(ContextInfo._stocks)}] [è­¦å‘Š] {stock}: æ— æ³•è§£ææ•°æ®æ ¼å¼")
                        continue

                    ContextInfo._collected_data.append({
                        'date': date_str,
                        'stock_code': stock,
                        'close': close_price
                    })
                    success_count += 1
                    print(f"  [{i}/{len(ContextInfo._stocks)}] [æˆåŠŸ] {stock}: {close_price:.4f}")
                else:
                    print(f"  [{i}/{len(ContextInfo._stocks)}] [è­¦å‘Š] {stock}: æœªåœ¨è¿”å›æ•°æ®ä¸­")
        else:
            print(f"[ERROR] get_history_data è¿”å›ç±»å‹å¼‚å¸¸: {type(hisdict)}")

    except Exception as e:
        print(f"[ERROR] get_history_data è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    print(f"[INFO] æœ¬ bar æˆåŠŸæ”¶é›† {success_count}/{len(ContextInfo._stocks)} åªè‚¡ç¥¨")
    print(f"[INFO] ç´¯è®¡æ”¶é›† {len(ContextInfo._collected_data)} æ¡æ•°æ®è®°å½•")

    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€åä¸€æ ¹ bar
    is_last_bar_func = getattr(ContextInfo, 'is_last_bar', lambda: False)
    is_last = is_last_bar_func()
    print(f"[DEBUG] is_last_bar() = {is_last}")

    # ä¿å­˜æ•°æ®çš„æ¡ä»¶ï¼š
    # 1. is_last_bar() è¿”å› Trueï¼Œæˆ–
    # 2. å·²æ”¶é›†è¶³å¤Ÿçš„æ•°æ®ï¼ˆä¾‹å¦‚ >= 40 æ¡ï¼Œå³ 8 å¤© * 5 åªè‚¡ç¥¨ï¼‰
    should_save = is_last or len(ContextInfo._collected_data) >= 40

    if should_save:
        print("\n" + "=" * 60)
        print("[iQuant] æ•°æ®æ”¶é›†å®Œæˆï¼Œå¼€å§‹ä¿å­˜...")
        print("=" * 60)

        if ContextInfo._collected_data:
            df = pd.DataFrame(ContextInfo._collected_data)

            print(f"[ç»Ÿè®¡] å…±æ”¶é›† {len(df)} æ¡æ•°æ®è®°å½•")
            print(f"   - è‚¡ç¥¨æ•°: {df['stock_code'].nunique()}")
            print(f"   - æ—¥æœŸæ•°: {df['date'].nunique()}")
            print(f"   - æ—¥æœŸèŒƒå›´: {df['date'].min()} è‡³ {df['date'].max()}")

            # æ‰“å°å‰å‡ æ¡å’Œåå‡ æ¡æ•°æ®
            print(f"\n[é¢„è§ˆ] å‰5æ¡æ•°æ®:")
            print(df.head(5).to_string(index=False))
            print(f"\n[é¢„è§ˆ] å5æ¡æ•°æ®:")
            print(df.tail(5).to_string(index=False))

            # ä¿å­˜åˆ° CSV
            os.makedirs(os.path.dirname(OUTPUT_CSV_PATH), exist_ok=True)
            df.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8')
            print(f"\n[æˆåŠŸ] âœ… æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_CSV_PATH}")
        else:
            print("[è­¦å‘Š] âš ï¸  æœªæ”¶é›†åˆ°ä»»ä½•æ•°æ®")

        print("=" * 60)
